---
title: "RMD_scallops_postmeeting"
author: "Alex Reich"
date: "2023-11-15"
output: html_document
---

## Take-away message/

PLOT TWIST: repairs made to the homer dredge in the middle of the survey. This seemed to drastically impact how the Homer dredge fished in relevance to the Kodiak dredge.

How this will impact the data: the FPC estimate will be the same but the CI will be larger. HOW TO CALCULATE THE CI WHEN THERES MORE GOING ON IN THE MODEL?? (add it or something?). With a large CI, the FPC will not be applied (the CI will overlap with 1.)  So we wont have an FPC to convert the older homer space data to kodiak space data.

I have info on which hauls were conducted after the repair.
I will do three things:

    0. Add the FIXED/ NOT FIXED factor to the data. This will indicate if it is before the homer fix or after the homer fi
    1. Do the randomized block ANOVA separately, for before and after the fix.
    2. Add FIX as a random or fixed effect
        2.1 test to see if a fixed effect or random effect would be more apprpriate4
        
        
## Take aways after analysis:

Biggest things were that (1) when I separate the data before and after the homer fix, the FPC results are drastically different. Suggesting one way before the fix (larger than one for homer-> Kodiak numerical space) and a different way after the fix (smaller than one for homer -> Kodiak numerical space), for both large and small scallops. Results here: significant FPC only for large(pre-fix), insignificant for large(post-fix) and small(both pre and post-fix).

And (2) that when I experiment with a pre/post fix factor as either a random or fixed effect in the model, things are...weird. It seems like the haul (blocking variable) completely masks all variability/contribution that would otherwise go to the pre/post fix factor. The fix is not statistically significant when haul is also in the model. Which I think is misleading, because from the results of the complete pre/post model separation, we know that the FPC is pushed in different directions before and after the fix event.

## Analysis

Load packages
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(dplyr)
library(RColorBrewer)
library(cowplot)
library(fishmethods)
library(viridis)
library(patchwork)
library(lme4)

set.seed(401)
```



Read in data. 
```{r}
## logbook data
logbook <- read.csv("./data_folder/new_data_dump/DredgeSurvey_FishLogData_CatchComparisonHauls.csv") 

## catch data
catch_raw <- read.csv("./data_folder/new_data_dump/DredgeSurvey_CatchData_CatchComparisonHauls.csv") 

## specimen data
specimen <- read.csv("./data_folder/new_data_dump/DredgeSurvey_ScallopBioData_CatchComparisonHauls.csv")

```

Get some stats
```{r}
#how many hauls?
length(unique(logbook$haul)) #48 paired hauls hauls, 

a <- logbook %>% filter(cruise_year==2023)
length(unique(a$haul)) #38 paired hauls in 2023

b<- logbook %>% filter(cruise_year==2022)
length(unique(b$haul)) #10 paired hauls in 2022
```


Data wrangle.
```{r}
# join logbook and catch in a way that preserves zero catches
tidyr::expand_grid(logbook,
            dplyr::distinct(dplyr::transmute(catch_raw, samp_grp, rcode, comname, whole_haul, sample_type))) %>% #expand logbook to all catch types
  dplyr::left_join(catch_raw) %>% #join with the catch.This connects catch vales to gear_code id.
  # fill in zero catches
  tidyr::replace_na(list(samp_cnt = 0, samp_wt = 0)) %>%
  # filter for scallops
  dplyr::filter(rcode == 74120) -> catch # now you have records of scallop catch per size class (samp_grp) per gear type
  

# cpue will be samp_wt (or count) / area_swept_sqnm. This code is calculating CPUE for both weight and number of scallops
catch_cpue <- catch %>% 
    dplyr::mutate(cpue_cnt = samp_cnt/area_swept_sqnm,
           cpue_wt = samp_wt/area_swept_sqnm)

# compute sample factor for specimen data 
specimen %>%
  # group by tow, samp grp, and size to get n at size
  dplyr::group_by(tow, samp_grp, shell_height) %>%
  dplyr::summarize(count = n()) %>%
  # compute number measured per tow
  dplyr::group_by(tow, samp_grp) %>%
  dplyr::mutate(n_measured = n()) %>% dplyr::ungroup() %>%
  # join to catch data
  dplyr::left_join(catch, by = c("tow", "samp_grp")) %>%
  # compute sample factor
  dplyr::mutate(sample_factor = samp_cnt * (count / n_measured)) -> specimen

#separate large and small scallops for cpue
large <- catch_cpue %>% dplyr::filter(samp_grp == 1)
small <- catch_cpue %>% dplyr::filter(samp_grp == 2)

##Remove where both hauls are 0.
large_2 <- large %>% #no change
    dplyr::group_by(haul) %>%
    dplyr::filter(!all(cpue_cnt == 0)) %>%
    dplyr::ungroup()

small_2 <- small %>% #filtered out where both dredges in a haul caught nothing
    dplyr::group_by(haul) %>%
    dplyr::filter(!all(cpue_cnt == 0)) %>%
    dplyr::ungroup()

#code the factors as factors
large_m <- large_2 %>%
           dplyr::mutate(gear_code = base::factor(gear_code, levels=c("5","1")), haul = base::factor(haul))  #the levels argument specifies that Kodiak(5) is the base, to compare Homer(1) against
    

small_m <- small_2 %>%
           dplyr::mutate(gear_code = base::factor(gear_code, levels=c("5", "1")), haul = base::factor(haul)) #levels=c(1,5) ?

```


Add the pre or post fix column

```{r}
Homer_fix_table <- data.frame(haul=c(141, 150, 152, 154, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197), Homer_fix=(base::rep("post", 15)))

Homer_fix_table$haul <- factor(Homer_fix_table$haul)

Haul_post <- factor(c(141, 150, 152, 154, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197))

Haul_pre <- unique(large_m$haul)
Haul_pre <- Haul_pre[-c(34:48)]

Homer_pre_fix <- data.frame(haul=Haul_pre, Homer_fix=(base::rep("pre", length(Haul_pre))))

#make the table
Homer_fix_T <- rbind(Homer_pre_fix, Homer_fix_table)
Homer_fix_T$Homer_fix <- factor(Homer_fix_T$Homer_fix)

#join into other tavles
#str(left_join(large_m, Homer_fix, by= "haul" ))
#str(large_m)

large_m <- left_join(large_m, Homer_fix_T, by= "haul" ) #something is up here. The join isnt working. Homer_fix_T instead?
small_m <- left_join(small_m, Homer_fix_T, by= "haul" )

#add the homer fix to the size tables too?
specimen$haul <- factor(specimen$haul)
specimen <- left_join(specimen, Homer_fix_T, by="haul")

```


Graph of stuff, without the pre/post fix, to see where the change over happens
```{r}
library(scales)

xx <- ggplot(large_m) + aes(x=factor(haul), y=cpue_cnt, color=bed_name, shape=factor(gear_code)) + geom_point(size=4) +scale_color_brewer(type="qual", palette=3)+ scale_shape_manual(values=c(19, 15),labels=c("Kodiak dredge", "Homer dredge"))+
    theme_cowplot()+
    xlab("Haul")+ ylab("CPUE")+ #cpue count
    ggtitle("Large scallops")+
    labs(shape="Gear type", color= "Bed name")+
    scale_y_continuous(labels= label_comma())#+
    #facet_wrap(~Homer_fix, nrow=2)

yy <- ggplot(small_m) + aes(x=factor(haul), y=cpue_cnt, color=bed_name, shape=factor(gear_code)) + geom_point(size=4) +scale_color_brewer(type="qual", palette=3)+ scale_shape_manual(values=c(19, 15),labels=c("Kodiak dredge", "Homer dredge"))+
    theme_cowplot()+
    xlab("Haul")+ ylab("CPUE")+ #cpue count
    ggtitle("Small scallops")+
    labs(shape="Gear type", color= "Bed name")+
    scale_y_continuous(labels= label_comma())#+
    #facet_wrap(~Homer_fix, nrow=2)

yyy <- yy + theme(legend.position ="none")

cplot <- xx/yyy + plot_layout(guides="collect")
cplot

#plot to show the full thing where we noticed the maintenence that happened

ggsave("figures/exploratory.tiff", plot=cplot, height=10, width=20, units="in")

```


Plot pre and post dredge fix - WIP, need to add the fix
```{r}
x <-ggplot(large_m) + aes(x=factor(haul), y=cpue_cnt, color=bed_name, shape=factor(gear_code)) + geom_point(size=4) +scale_color_brewer(type="qual", palette=3)+ scale_shape_manual(values=c(19, 15),labels=c("Kodiak dredge", "Homer dredge"))+
    theme_cowplot()+
    xlab("Haul")+ ylab("CPUE")+
    ggtitle("Large scallops")+
    labs(shape="Gear type", color= "Bed name")+
    facet_wrap(~Homer_fix, nrow=2)+
    scale_y_continuous(labels= label_comma())



y<- ggplot(small_m) + aes(x=factor(haul), y=cpue_cnt, color=bed_name, shape=factor(gear_code)) + geom_point(size=4) +scale_color_brewer(type="qual", palette=3)+ scale_shape_manual(values=c(19, 15),labels=c("Kodiak dredge", "Homer dredge"))+
    theme_cowplot()+
    xlab("Haul")+ ylab("CPUE")+
    ggtitle("Small scallops")+
    labs(shape="Gear type", color= "Bed name")+
    facet_wrap(~Homer_fix, nrow=2)+
    scale_y_continuous(labels= label_comma())
x
y

x/y +plot_layout(guides="collect")

ggsave("figures/Split anova L.jpg", plot=x, height=10, width=20, units="in")
ggsave("figures/Split anova S.jpg", plot=y, height=10, width=20, units="in")
```



Split into pre and post- repair FPC tests
make sure the FPC is homer space -> kodiak space
```{r}
options(contrasts = rep("contr.sum", 2))

#large scallops
l_pre <- large_m %>% filter(Homer_fix == "pre")
l_post <- large_m %>% filter(Homer_fix == "post")


mod_L_pre_cnt <- lm(log(cpue_cnt+1) ~ gear_code + haul, data=l_pre)
mod_L_post_cnt <- lm(log(cpue_cnt+1) ~ gear_code + haul, data=l_post)

sum_L_pre <- summary(mod_L_pre_cnt)
sum_L_post <- summary(mod_L_post_cnt)

#small scallops

s_pre <- small_m %>% filter(Homer_fix == "pre")
s_post <- small_m %>% filter(Homer_fix == "post")


mod_S_pre_cnt <- lm(log(cpue_cnt+1) ~ gear_code + haul, data=s_pre)
mod_S_post_cnt <- lm(log(cpue_cnt+1) ~ gear_code + haul, data=s_post)

sum_S_pre <- summary(mod_S_pre_cnt)
sum_S_post <- summary(mod_S_post_cnt)

##################################
#get FPC estimator
###########################


#large pre repair
s_L_pre <- sum_L_pre$coefficients[2,2]  
g_L_pre <- sum_L_pre$coefficients[2,1]

FPC_large_pre <- exp(2*g_L_pre*(1+(0.5*(s_L_pre^2)))) #1.87

#large post repair
s_L_post <- sum_L_post$coefficients[2,2]  
g_L_post <- sum_L_post$coefficients[2,1]

FPC_large_post <- exp(2*g_L_post*(1+(0.5*(s_L_post^2)))) #0.88 #oof, pre and post repair are very different FPC's.

#small pre repair
s_S_pre <- sum_S_pre$coefficients[2,2]  
g_S_pre <- sum_S_pre$coefficients[2,1]

FPC_small_pre <- exp(2*g_S_pre*(1+(0.5*(s_S_pre^2)))) #1.64

#small post repair
s_S_post <- sum_S_post$coefficients[2,2]  
g_S_post <- sum_S_post$coefficients[2,1]

FPC_small_post <- exp(2*g_S_post*(1+(0.5*(s_S_post^2))))#0.87




##########################
#get confidence intervals
#####################
upper_CI_L_pre <- exp(2*g_L_pre + 1.96*2*s_L_pre)
lower_CI_L_pre <- exp(2*g_L_pre - 1.96*2*s_L_pre)

upper_CI_L_post <- exp(2*g_L_post + 1.96*2*s_L_post)
lower_CI_L_post <- exp(2*g_L_post - 1.96*2*s_L_post)

upper_CI_S_pre <- exp(2*g_S_pre + 1.96*2*s_S_pre)
lower_CI_S_pre <- exp(2*g_S_pre - 1.96*2*s_S_pre)

upper_CI_S_post <- exp(2*g_S_post + 1.96*2*s_S_post)
lower_CI_S_post <- exp(2*g_S_post - 1.96*2*s_S_post)








#get the combined FPC as well. for scallop count.
#yes
##large scallops combined FPC

mod_L_cnt <- lm(log(cpue_cnt+1) ~ gear_code + haul, data=large_m)

sum_L_cnt <- summary(mod_L_cnt)


##small scallops combined FPC
mod_S_cnt <- lm(log(cpue_cnt+1) ~ gear_code + haul, data=small_m)

sum_S_cnt <- summary(mod_S_cnt)

##FPC's
#large
s_L <- sum_L_cnt$coefficients[2,2]  
g_L <- sum_L_cnt$coefficients[2,1]

FPC_large_cnt <- exp(2*g_L*(1+(0.5*(s_L^2)))) #1.472
#small

s_S <- sum_S_cnt$coefficients[2,2]  
g_S <- sum_S_cnt$coefficients[2,1]

FPC_small_cnt <- exp(2*g_S*(1+(0.5*(s_S^2)))) #1.321

##get confidence intervals
#large
upper_CI_L <- exp(2*g_L + 1.96*2*s_L)
lower_CI_L <- exp(2*g_L - 1.96*2*s_L)
#small
upper_CI_S <- exp(2*g_S + 1.96*2*s_S)
lower_CI_S <- exp(2*g_S - 1.96*2*s_S)


upper_CI <- c(upper_CI_L_pre, upper_CI_L_post, upper_CI_L, upper_CI_S_pre, upper_CI_S_post, upper_CI_S )
lower_CI <- c(lower_CI_L_pre, lower_CI_L_post, lower_CI_L, lower_CI_S_pre,lower_CI_S_post, lower_CI_S)

###############
#make the table
##############

FPC <- c(FPC_large_pre, FPC_large_post, FPC_large_cnt, FPC_small_pre, FPC_small_post, FPC_small_cnt)
Category <- factor(x=c("large(pre)" , "large(post)", "large(combined)", "small(pre)", "small(post)", "small(combined)"), levels=c("large(pre)" , "large(post)", "large(combined)", "small(pre)", "small(post)", "small(combined)"))

scallop_FPC_table <- data.frame(Category, FPC)


scallop_FPC_table$Upper_CI <- upper_CI
scallop_FPC_table$Lower_CI <- lower_CI

scallop_FPC_table$repair <- factor(x=c("pre", "post", "combined", "pre", "post", "combined"), levels=c("combined","pre", "post"))

scallop_FPC_table#$repair <- reorder(scallop_FPC_table$repair, X=c("combined", "pre", "post"))



write.csv(scallop_FPC_table, "results/Scallop FPC Table.csv")

#oof. pre conclusions are different from post conclusions for large. No FPC applied for small, but still, oof.


####
#outliers??
####
plot(mod_L_pre_cnt) #2 outliers
plot(mod_L_post_cnt) #0 outliers

plot(mod_S_pre_cnt) # 4 outliers
plot(mod_S_post_cnt) #0 outliers

plot(mod_L_cnt) #2 outliers
plot(mod_S_cnt) #4 outliers


```


FPC graph
```{r}
library(RColorBrewer)
#graph the FPC's and their confidence intervals, shwoing how they comapre to each other and also to 1.
FPC_graph <- ggplot(scallop_FPC_table) + aes(x=Category, y=FPC) + 
    geom_errorbar(aes(ymin=Lower_CI, ymax=Upper_CI)) +
    geom_point(size=4, aes(color=repair))+
    geom_hline(aes(yintercept=1), color="red", size=1, linetype="dashed")+
    theme_cowplot()+
    scale_color_brewer(palette = "Set1")+
    labs(color= "Homer dredge repair status")+
    scale_y_continuous( limits=c(0.6,3.5), expand=c(0,0))

FPC_graph_document <- ggplot(scallop_FPC_table) + aes(x=Category, y=FPC) +  #cleaning up fig for the paper
    geom_errorbar(aes(ymin=Lower_CI, ymax=Upper_CI)) +
    geom_point(size=4, aes(color=repair))+
    geom_hline(aes(yintercept=1), color="red", size=1, linetype="dashed")+
    theme_cowplot()+
    scale_color_brewer(palette = "Set1")+
    labs(color= "Homer dredge repair status", x=element_blank())+
    scale_y_continuous( limits=c(0.6,3.5), expand=c(0,0), breaks=c(1,2,3)) +
    ggtitle("Randomized block ANOVA")
    
#add cofidence intervals/error bars too. Geom_errorbar?
#and add a line at y=1 please
#manusal color scale
#get rid of "repair" or name it somethign better
#switch the pre and post factor order, so it goes pre then post

#ggsave("figures/FPC_graph.jpg",plot=FPC_graph, height=5, width=10, units="in")

```


Kappenman's analysis (see scallops_8)
```{r}
f_kapp_AR <- function(data) {
    #deleted args from function: ves1, ves2, vessel_name = "vessel"
  
  # ensure vessel and cpue columns are properly named
  #data %>%
   # rename(vessel = as.name(vessel_name),
    #       cpue = as.name(cpue_name)) -> data
  
  # pivot data to wide format (i.e., in pairs)
 # data %>%
    #pivot_wider(names_from = vessel, values_from = cpue_wt) -> data
  # extract cpue vectors from data
 # cpue1 = data %>% pull(as.name(ves1)) # standard vessel
 # cpue2 = data %>% pull(as.name(ves2)) 
  
  #alex code
  tmp1 = data %>% filter(gear_code==5)
  cpue1 <- tmp1$cpue_cnt
  
  tmp2 = data %>% filter(gear_code==1)
  cpue2 <- tmp2$cpue_cnt
  
  # call fishmethods::fpc
  kapp = try(fishmethods::fpc(cpue1, cpue2, method = 4, kapp_zeros = "ind", boot_type = "unpaired"), silent = T)
  #kapp = try(fishmethods::fpc(cpue1, cpue2, method = 4), silent = T)
  #AR adjusted so that cpue 2 is the first number and cpue 1 is the second number
  #cpue 2 is for gear type 5 (new dredge)
  #cpue 1 is for gear type 1(old dredge)
  
  # organize results
  if(class(kapp) == "try-error"){
    tibble(n = NA,
           cpue1 = NA,
           cpue2 = NA,
           fpc = NA,
           boot_se = NA,
           boot_l95 = NA,
           boot_u95 = NA) -> out
  } else{
    kapp %>%
      as_tibble() %>%
      rename(n = n1,
             cpue1 = `mean cpue1`,
             cpue2 = `mean cpue2`,
             fpc = FPC,
             boot_se = Boot_SE,
             boot_l95 = `Boot_95%_LCI`,
             boot_u95 = `Boot_95%_UCI`) %>%
      dplyr::select(n, cpue1, cpue2, fpc, boot_se, boot_l95, boot_u95) -> out
  }
    
  # fix names
  #names(out)[2] = paste0(ves1, "_cpue")
  #names(out)[3] = paste0(ves2, "_cpue")
  
  # output
  return(out)
  
}

#ok ok, that should be a functional function. f_kapp_AR

kapp_cnt_L <- f_kapp_AR(data=large_m)
kapp_cnt_S <- f_kapp_AR(data=small_m)

kapp_L_pre <- f_kapp_AR(data=l_pre)
kapp_L_post <- f_kapp_AR(data=l_post)

kapp_S_pre <- f_kapp_AR(data=s_pre)
kapp_S_post <- f_kapp_AR(data=s_post)

kapp_tibble <- rbind(kapp_cnt_L, kapp_cnt_S, kapp_L_pre, kapp_L_post, kapp_S_pre, kapp_S_post)
kapp_tibble

kapp_tibble$Category <- factor(x=c("large(combined)", "small(combined)", "large(pre)" , "large(post)", "small(pre)", "small(post)"), levels=c("large(pre)" , "large(post)", "large(combined)", "small(pre)", "small(post)", "small(combined)"))
kapp_tibble$repair <- factor(x=c("combined", "combined", "pre", "post", "pre", "post"), levels=c("combined", "pre", "post"))    

kapp_tibble

write.csv(x=kapp_tibble, file= "results/Kapp tibble.csv")

```


Graph Kappenman's

Mean and SD for both kodiak and homer scallops hauls, sep by L and S scallops.
- supplmental slide
- MSE for just the randomzied block ANOVA, for now
```{r}
#
(kappgraph <- ggplot(kapp_tibble) + aes(x=Category, y=fpc) + 
    geom_errorbar(aes(ymin=boot_l95, ymax=boot_u95), color="darkgrey") +
    geom_point(size=4, aes(color=repair), alpha=0.7)+
    geom_hline(aes(yintercept=1), color="red", size=1, linetype="dashed", alpha=0.7)+
    theme_cowplot()+
    scale_color_brewer(palette = "Set1")+
    labs(color= "Homer dredge repair status", y="FPC")+
     theme(legend.position ="none"))+
    scale_y_continuous(breaks=c(1, 2,3, 4), limits=c(0.2,4), expand=c(0,0))

kappgraph_document <- ggplot(kapp_tibble) + aes(x=Category, y=fpc) + 
    geom_errorbar(aes(ymin=boot_l95, ymax=boot_u95)) +
    geom_point(size=4, aes(color=repair))+
    geom_hline(aes(yintercept=1), color="red", size=1, linetype="dashed")+
    theme_cowplot()+
    scale_color_brewer(palette = "Set1")+
    labs(color= "Homer dredge repair status", y="FPC")+
     theme(legend.position ="none")+
    scale_y_continuous(breaks=c(1, 2,3, 4), limits=c(0.2,4), expand=c(0,0)) +
    ggtitle("Kappenman")

```

Combined FPC graph, both for RB ANOVA and kapp
```{r}
#version for the ppt
(FPC_combined_graph <- FPC_graph/kappgraph + plot_layout(guides="collect"))

#making the version for the document
FPC_com_doc <- FPC_graph_document/kappgraph_document +  plot_layout(guides="collect")

ggsave("figures/FPC_combined_graph.jpg", plot=FPC_combined_graph, height=5, width=10, units="in")
ggsave("figures/FPC_combined_graph_doc.jpg", plot= FPC_com_doc, height=6, width=10, units="in")
```


MSE for RB ANOVA
```{r}
f_mse_sim_AR1 <- function(data, n, method){ ##Should this function use both homer and kodiak cpue data or just kodiak cpue data?? 
  
  # pull cpue from data
  data %>%
    pull(cpue_wt) -> cpue  #should this be all the cpue or just for the uncorrected? 
    
  # compute parameters of lognormal dist
  mu = log(mean(cpue)) - 0.5*log(1+(sd(cpue)/mean(cpue))^2) #ok if this is global? OR should these values be just for Kodiak?? We use the total CPUE to calc the correction?? Should this function use both homer and kodiak cpue data or just kodiak cpue data?? 
  
  var = log(1+(sd(cpue)/mean(cpue))^2) 
  
  # check pdf
  #hist(cpue, freq = F)
  #lines(density(rlnorm(1000, meanlog = mu, sdlog = sqrt(var))), col = 2)
  
  cpue_u = NULL
  cpue_c = NULL
  mse_u = NULL
  mse_c = NULL
  fpd = seq(0.1, 2, 0.1) 
  for(i in 1:length(fpd)){
    for(j in 1:200){
      # simulate cpue standard vessel aka the KODIAK dredge
      kod_sim = rlnorm(n, meanlog = mu, sdlog = sqrt(var)) #simulations for KODIAK(updated) #SHOULD THIS INDICATE ACTUAL mu values for kodiak??
      # simulate cpue non-standard vessel aka the Kodiak dredge
      hom_sim = rlnorm(n, meanlog = mu, sdlog = sqrt(var)) * fpd[i] #simulations for HOMER(updated)
      # estimate FPC
      fpc <- fpc(cpue1 = kod_sim, cpue2 = hom_sim, method = method, nboot = 0, kapp_zeros = "ind") #ah. here we can choose if we want method 2 (anova) or 4(kappenmans). I altered here to make kodiak the default

      # join vessel cpues to one vector
      ## uncorrected
      survey_u = c(kod_sim, hom_sim)
      ## corrected
      survey_c = c(kod_sim, (hom_sim * fpc$FPC))  # scale to standard vessel
      
      # compute means of uncorrected and corrected data
      cpue_u[j] = mean(survey_u)
      cpue_c[j] = mean(survey_c)
      
    }
    mse_u[i] = mean((cpue_u - mean(cpue))^2)
    mse_c[i] = mean((cpue_c - mean(cpue))^2)
  }
  
  tibble(fpd = fpd,
         mse_u = mse_u,
         mse_c = mse_c)
  
}


### simulation plot function AR
f_sim_plot <- function(data, fpc){
  # plot data
  data %>%
    pivot_longer(cols=c("mse_u", "mse_c"), names_to = "sim", values_to = "mse") %>%
    mutate(sim = case_when(sim == "mse_u" ~ "Uncorrected",
                           sim == "mse_c" ~ "Corrected")) %>%
    ggplot()+
    geom_point(aes(x = fpd, y = mse, color = sim), alpha = 0.3)+
    geom_smooth(aes(x = fpd, y = mse, color = sim), method = "lm",formula = y ~ poly(x, 2), se = F)+
   # scale_color_manual(values = cb_palette[c(1,3)])+
    geom_vline(aes(xintercept = fpc), linetype = 2)+ #add in later? PROBS. AR
    labs(x = "Fishing Power Difference", y = "MSE", color = NULL)+
    scale_x_continuous(breaks = seq(0, 2, 0.2), limits = c(0, 2)) -> x
  # save
 # ggsave(paste0(path_prefix, spp_name, ".png"), plot = x, width = 5, height = 4, units = "in")
  return(x)
}

### now taht functions are set up, get the results and graphs for my 6 categories
scallop_FPC_table
scallop_FPC_table[3,2]

length(large_m$haul)/2
RB_ANOVA_mse_large <- f_mse_sim_AR1(data=large_m, n=48, method=2) #n is the # of paired hauls
plot_RB_ANOVA_mse_large<- f_sim_plot(data=RB_ANOVA_mse_large, fpc=scallop_FPC_table[3,2])

length(small_m$haul)/2 #double check #'s. Why so many removed from small?? Both were 0 for small scallops, that many? #ok there werw a lot of 0's...
RB_ANOVA_mse_small <- f_mse_sim_AR1(data=small_m, n=44, method=2) #n was diff for large and small scallops
plot_RB_ANOVA_mse_small <- f_sim_plot(data=RB_ANOVA_mse_small, fpc=scallop_FPC_table[6,2]) #was FPC

length(l_pre$haul)/2 
RB_ANOVA_mse_large_pre <- f_mse_sim_AR1(data=l_pre, n=33, method=2) #n is different. What is n?
plot_RB_ANOVA_mse_large_pre<- f_sim_plot(data=RB_ANOVA_mse_large_pre, fpc=scallop_FPC_table[1,2])

length(l_post$haul)/2
RB_ANOVA_mse_large_post <- f_mse_sim_AR1(data=l_post, n=15, method=2) 
plot_RB_ANOVA_mse_large_post<- f_sim_plot(data=RB_ANOVA_mse_large_post, fpc=scallop_FPC_table[2,2])


length(s_pre$haul)/2
RB_ANOVA_mse_small_pre <- f_mse_sim_AR1(data=s_pre, n=29, method=2) #n is different. What is n?
plot_RB_ANOVA_mse_small_pre<- f_sim_plot(data=RB_ANOVA_mse_small_pre, fpc=scallop_FPC_table[4,2])

length(s_post$haul)/2
RB_ANOVA_mse_small_post <- f_mse_sim_AR1(data=s_post, n=15, method=2) 
plot_RB_ANOVA_mse_small_post<- f_sim_plot(data=RB_ANOVA_mse_small_post, fpc=scallop_FPC_table[5,2])


plot_RB_ANOVA_mse_large
plot_RB_ANOVA_mse_small
plot_RB_ANOVA_mse_large_pre
plot_RB_ANOVA_mse_large_post
plot_RB_ANOVA_mse_small_pre
plot_RB_ANOVA_mse_small_post
#and then SAVE ENVIRONMENT!!

```
Save the MSE plots
```{r}
comb1 <-plot_RB_ANOVA_mse_large_pre + plot_RB_ANOVA_mse_large_post + plot_RB_ANOVA_mse_large

comb2 <-plot_RB_ANOVA_mse_small_pre + plot_RB_ANOVA_mse_small_post + plot_RB_ANOVA_mse_small

ggsave("figures/MSE_L.jpg", plot=comb1, height=3, width=12, units="in")
ggsave("figures/MSE_S.jpg", plot=comb2, height=3, width=12, units="in")

#once I save these, I can put them in the ppt
```



Density graph exploration
```{r}
#any necessary data wrangling?

#overall density comparison: homer v kodiak (see scallops_8)
##graph
bbb<-ggplot(specimen) + aes(x=shell_height, color=factor(gear_code), group=factor(gear_code)) + geom_density(aes(weight=sample_factor), linewidth=1.2, alpha=0.5) + #is sample factor based off of # cpue? needs to be. Yes, we are good there.
#facet_wrap(~gear_code, ncol=1) +
theme_cowplot()+ 
scale_color_manual(values = c("blue", "orange"), labels=c("Homer dredge", "Kodiak dredge"))+ #might want to change colors to match color scheme
xlab("Shell height (mm)")+
ylab("Density")+
#ggtitle("Shell height density, all scallop sizes")+
labs(color=NULL)+
    theme_cowplot()#+
    #scale_x_continuous(breaks=c(50, 100, 150, 200), limits=c(0, 200), expand=c(0,0))+
    #scale_y_continuous(breaks=c(0.01, 0.02, 0.03, 0.04), limits=c(0, 0.04))

ggsave("figures/Density plot.jpg", bbb, height=5, width=10)

##formal density test
library(Ecume)

homer_spec <- specimen %>% filter(gear_code==1)
kodiak_spec <- specimen %>% filter(gear_code==5)
#ks.test(x=homer_spec$shell_height, y=kodiak_spec$shell_height, alternative="two.sided") #not weighted test

ks_weighted_result_4 <- Ecume::ks_test(x=homer_spec$shell_height, y=kodiak_spec$shell_height, thresh= 0, w_x=(homer_spec$sample_factor/100),  w_y=(kodiak_spec$sample_factor/100)) #weighted test

ks_weighted_result_4

#pre and post homer dredge fix: how did fixing homer dredge change density
pre_homer_spec <- homer_spec %>% filter(Homer_fix == "pre")
post_homer_spec <- homer_spec %>% filter(Homer_fix == "post")

homer_spec$Homer_fix <- factor(homer_spec$Homer_fix, levels=c("pre", "post"))

ccc<-ggplot(homer_spec) + aes(x=shell_height, color=factor(Homer_fix), group=factor(Homer_fix)) + geom_density(aes(weight=sample_factor), linewidth=1.2, alpha=0.5) + #is sample factor based off of # cpue? needs to be. Yes, we are good there.
#facet_wrap(~gear_code, ncol=1) +
theme_cowplot()+ 
scale_color_manual(values = c("royalblue", "goldenrod"), labels=c("Pre", "Post"))+ #might want to change colors to match color scheme
xlab("Shell height")+
ylab("Density")+
ggtitle("Shell height density, all scallop sizes")+
labs(color=NULL)+
    theme_cowplot()
ccc

#formal density test, pre and post homer? 

ks_weighted_result_prepost <- Ecume::ks_test(x=pre_homer_spec$shell_height, y=post_homer_spec$shell_height, thresh= 0, w_x=(pre_homer_spec$sample_factor/100),  w_y=(post_homer_spec$sample_factor/100)) #weighted test

ks_weighted_result_prepost

#ggsave("figures/Density plot Homer fix.jpg", ccc, height=5, width=10)


```


Kodiak dredde consistency aside.
```{r}
#setup
kodiak_spec$Homer_fix <- factor(kodiak_spec$Homer_fix, levels=c("pre", "post"))

#graph
ddd<-ggplot(kodiak_spec) + aes(x=shell_height, color=factor(Homer_fix), group=factor(Homer_fix)) + geom_density(aes(weight=sample_factor), linewidth=1.2, alpha=0.5) + #is sample factor based off of # cpue? needs to be. Yes, we are good there.
#facet_wrap(~gear_code, ncol=1) +
theme_cowplot()+ 
#scale_color_manual(values = c("royalblue", "goldenrod"), labels=c("Pre", "Post"))+ #might want to change colors to match color scheme
xlab("Shell height")+
ylab("Density")+
ggtitle("Shell height density")+
labs(color=NULL)+
    theme_cowplot()
ddd
ccc

#facet wrap by year
ggplot(kodiak_spec) + aes(x=shell_height, color=factor(Homer_fix), group=factor(Homer_fix)) + geom_density(aes(weight=sample_factor), linewidth=1.2, alpha=0.5) + #is sample factor based off of # cpue? needs to be. Yes, we are good there.
#facet_wrap(~gear_code, ncol=1) +
theme_cowplot()+ 
#scale_color_manual(values = c("royalblue", "goldenrod"), labels=c("Pre", "Post"))+ #might want to change colors to match color scheme
xlab("Shell height")+
ylab("Density")+
ggtitle("Shell height density")+
labs(color=NULL)+
    theme_cowplot()+
    facet_wrap(~cruise_year)


ggplot(homer_spec) + aes(x=shell_height, color=factor(Homer_fix), group=factor(Homer_fix)) + geom_density(aes(weight=sample_factor), linewidth=1.2, alpha=0.5) + #is sample factor based off of # cpue? needs to be. Yes, we are good there.
#facet_wrap(~gear_code, ncol=1) +
theme_cowplot()+ 
#scale_color_manual(values = c("royalblue", "goldenrod"), labels=c("Pre", "Post"))+ #might want to change colors to match color scheme
xlab("Shell height")+
ylab("Density")+
ggtitle("Shell height density, all scallop sizes")+
labs(color=NULL)+
    theme_cowplot()+
    facet_wrap(~cruise_year)
```



OVerall summary stats
Mean, sd, etc
```{r}


```



Experiment below:

Random effect or fixed effect (test for it) -  Homer dredge fix
Random effect did not work
Fixed effect was masked by the randomized block design
```{r}
#Q:
##do  I need to apply the options argument here, to switch it back to default??
##Also, do I calculate the FPC when there's other stuff going on... add this stuff to the uncertainty??
#############################################################################################################

large_m$Homer_fix <- factor(large_m$Homer_fix)
small_m$Homer_fix <- factor(small_m$Homer_fix)

#first establish the global model
##large
global_L <- lm(log(cpue_cnt+1) ~ gear_code + haul, data=large_m)

##small
global_S <- lm(log(cpue_cnt+1) ~ gear_code + haul, data=small_m)

#test random effects
random_L <- lmer(log(cpue_cnt+1) ~ gear_code + haul + (1|Homer_fix), data=large_m, REML=T) #this is probs the way to go
##I get a warning about the hessian matrix and singularity, indicating that I do not have enough data for a mixed effects model
summary(random_L)
summary(global_L)
ranef(random_L) #weird numbers

random_S <- lmer(log(cpue_cnt+1) ~ gear_code + haul + (1|Homer_fix), data=small_m, REML=T) 
#ok but this one runs without a hessian error.
summary(random_S)
ranef(random_S) #weird, saying the additional error from the Homer_fix is really really small, and I'm not so sure that is correct.
#maybe haul absorbs a lot of this error?

#try other model variations


#fixed effect model
fixed_L <- lm(log(cpue_cnt+1) ~ gear_code + haul + factor(Homer_fix), data=large_m)
AIC(global_L, random_L) #says mixed model is better of these two
AIC(global_L, fixed_L) #says thet're... the same
##haul is absorbing all of the change, masking homer_fix.
###hmm what to do about this
summary(fixed_L)

fixed_S <- lm(log(cpue_cnt+1) ~ gear_code + haul + factor(Homer_fix), data=small_m)
AIC(global_S, random_S) #nothing wins
AIC(global_S, fixed_S) #neitehr wins


#what if I take away haul
mod_L_no_haul <- lm(log(cpue_cnt+1) ~ gear_code + factor(Homer_fix), data=large_m)
mod_S_no_haul <- lm(log(cpue_cnt+1) ~ gear_code + factor(Homer_fix), data=small_m)

summary(mod_L_no_haul)
summary(mod_S_no_haul)

#gear code is not sig, when haul is removed. Duh, should have expected taht

```


experiemnt: remove outliers
- we know in cases where one haul is 0 and the other caught somethign, that is an outlier situation.
-we've already removed cases were both hauls were 0 in a paired haul
- remove outleirs and see if resutls (CI's too) look teh same
```{r}
#outleir ID
plot(mod_L_pre_cnt) #2 outliers
plot(mod_L_post_cnt) #0 outliers

plot(mod_S_pre_cnt) # 4 outliers
plot(mod_S_post_cnt) #0 outliers

plot(mod_L_cnt) #2 outliers
plot(mod_S_cnt) #4 outliers

#remove them

no_outliers_l <- large_m[-c(21,22),]
no_outliers_s <- small_m[-c(23,24,35,36),]
```

Results but without the outliers
```{r}
options(contrasts = rep("contr.sum", 2))

#large scallops
l_pre <- no_outliers_l %>% filter(Homer_fix == "pre")
l_post <- no_outliers_l %>% filter(Homer_fix == "post")


mod_L_pre_cnt <- lm(log(cpue_cnt+1) ~ gear_code + haul, data=l_pre)
mod_L_post_cnt <- lm(log(cpue_cnt+1) ~ gear_code + haul, data=l_post)

sum_L_pre <- summary(mod_L_pre_cnt)
sum_L_post <- summary(mod_L_post_cnt)

#small scallops

s_pre <- no_outliers_s %>% filter(Homer_fix == "pre")
s_post <- no_outliers_s %>% filter(Homer_fix == "post")


mod_S_pre_cnt <- lm(log(cpue_cnt+1) ~ gear_code + haul, data=s_pre)
mod_S_post_cnt <- lm(log(cpue_cnt+1) ~ gear_code + haul, data=s_post)

sum_S_pre <- summary(mod_S_pre_cnt)
sum_S_post <- summary(mod_S_post_cnt)

##################################
#get FPC estimator
###########################


#large pre repair
s_L_pre <- sum_L_pre$coefficients[2,2]  
g_L_pre <- sum_L_pre$coefficients[2,1]

FPC_large_pre <- exp(2*g_L_pre*(1+(0.5*(s_L_pre^2)))) #1.87

#large post repair
s_L_post <- sum_L_post$coefficients[2,2]  
g_L_post <- sum_L_post$coefficients[2,1]

FPC_large_post <- exp(2*g_L_post*(1+(0.5*(s_L_post^2)))) #0.88 #oof, pre and post repair are very different FPC's.

#small pre repair
s_S_pre <- sum_S_pre$coefficients[2,2]  
g_S_pre <- sum_S_pre$coefficients[2,1]

FPC_small_pre <- exp(2*g_S_pre*(1+(0.5*(s_S_pre^2)))) #1.64

#small post repair
s_S_post <- sum_S_post$coefficients[2,2]  
g_S_post <- sum_S_post$coefficients[2,1]

FPC_small_post <- exp(2*g_S_post*(1+(0.5*(s_S_post^2))))#0.87




##########################
#get confidence intervals
#####################
upper_CI_L_pre <- exp(2*g_L_pre + 1.96*2*s_L_pre)
lower_CI_L_pre <- exp(2*g_L_pre - 1.96*2*s_L_pre)

upper_CI_L_post <- exp(2*g_L_post + 1.96*2*s_L_post)
lower_CI_L_post <- exp(2*g_L_post - 1.96*2*s_L_post)

upper_CI_S_pre <- exp(2*g_S_pre + 1.96*2*s_S_pre)
lower_CI_S_pre <- exp(2*g_S_pre - 1.96*2*s_S_pre)

upper_CI_S_post <- exp(2*g_S_post + 1.96*2*s_S_post)
lower_CI_S_post <- exp(2*g_S_post - 1.96*2*s_S_post)








#get the combined FPC as well. for scallop count.
#yes
##large scallops combined FPC

mod_L_cnt <- lm(log(cpue_cnt+1) ~ gear_code + haul, data=no_outliers_l)

sum_L_cnt <- summary(mod_L_cnt)


##small scallops combined FPC
mod_S_cnt <- lm(log(cpue_cnt+1) ~ gear_code + haul, data=no_outliers_s)

sum_S_cnt <- summary(mod_S_cnt)

##FPC's
#large
s_L <- sum_L_cnt$coefficients[2,2]  
g_L <- sum_L_cnt$coefficients[2,1]

FPC_large_cnt <- exp(2*g_L*(1+(0.5*(s_L^2)))) #1.472
#small

s_S <- sum_S_cnt$coefficients[2,2]  
g_S <- sum_S_cnt$coefficients[2,1]

FPC_small_cnt <- exp(2*g_S*(1+(0.5*(s_S^2)))) #1.321

##get confidence intervals
#large
upper_CI_L <- exp(2*g_L + 1.96*2*s_L)
lower_CI_L <- exp(2*g_L - 1.96*2*s_L)
#small
upper_CI_S <- exp(2*g_S + 1.96*2*s_S)
lower_CI_S <- exp(2*g_S - 1.96*2*s_S)


upper_CI <- c(upper_CI_L_pre, upper_CI_L_post, upper_CI_L, upper_CI_S_pre, upper_CI_S_post, upper_CI_S )
lower_CI <- c(lower_CI_L_pre, lower_CI_L_post, lower_CI_L, lower_CI_S_pre,lower_CI_S_post, lower_CI_S)

###############
#make the table
##############

FPC <- c(FPC_large_pre, FPC_large_post, FPC_large_cnt, FPC_small_pre, FPC_small_post, FPC_small_cnt)
Category <- factor(x=c("large(pre)" , "large(post)", "large(combined)", "small(pre)", "small(post)", "small(combined)"), levels=c("large(pre)" , "large(post)", "large(combined)", "small(pre)", "small(post)", "small(combined)"))

scallop_FPC_table <- data.frame(Category, FPC)


scallop_FPC_table$Upper_CI <- upper_CI
scallop_FPC_table$Lower_CI <- lower_CI

scallop_FPC_table$repair <- factor(x=c("pre", "post", "combined", "pre", "post", "combined"), levels=c("combined","pre", "post"))

scallop_FPC_table#$repair <- reorder(scallop_FPC_table$repair, X=c("combined", "pre", "post"))



write.csv(scallop_FPC_table, "results/Scallop FPC Table without outliers.csv")

#FPC graph without outliers
(FPC_graph_document <- ggplot(scallop_FPC_table) + aes(x=Category, y=FPC) +  #cleaning up fig for the paper
    geom_errorbar(aes(ymin=Lower_CI, ymax=Upper_CI)) +
    geom_point(size=4, aes(color=repair))+
    geom_hline(aes(yintercept=1), color="red", size=1, linetype="dashed")+
    theme_cowplot()+
    scale_color_brewer(palette = "Set1")+
    labs(color= "Homer dredge repair status", x=element_blank())+
    scale_y_continuous( limits=c(0.6,3.5), expand=c(0,0), breaks=c(1,2,3)) +
    ggtitle("Randomized block ANOVA without outleirs"))
    

ggsave("figures/FPC_graph_nooutliers.jpg",plot=FPC_graph_document, height=5, width=10, units="in")
#error bars are smaller but no chagne in results
```


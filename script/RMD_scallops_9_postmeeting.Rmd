---
title: "RMD_scallops_postmeeting"
author: "Alex Reich"
date: "2023-11-15"
output: html_document
---

## Take-away message/

PLOT TWIST: repairs made to the homer dredge in the middle of the survey. This seemed to drastically impact how the Homer dredge fished in relevance to the Kodiak dredge.

How this will impact the data: the FPC estimate will be the same but the CI will be larger. HOW TO CALCULATE THE CI WHEN THERES MORE GOING ON IN THE MODEL?? (add it or something?). With a large CI, the FPC will not be applied (the CI will overlap with 1.)  So we wont have an FPC to convert the older homer space data to kodiak space data.

I have info on which hauls were conducted after the repair.
I will do three things:

    0. Add the FIXED/ NOT FIXED factor to the data. This will indicate if it is before the homer fix or after the homer fi
    1. Do the randomized block ANOVA separately, for before and after the fix.
    2. Add FIX as a random or fixed effect
        2.1 test to see if a fixed effect or random effect would be more apprpriate4
        
        
## Take aways after analysis:

Biggest things were that (1) when I separate the data before and after the homer fix, the FPC results are drastically different. Suggesting one way before the fix (larger than one for homer-> Kodiak numerical space) and a different way after the fix (smaller than one for homer -> Kodiak numerical space), for both large and small scallops. Results here: significant FPC only for large(pre-fix), insignificant for large(post-fix) and small(both pre and post-fix).

And (2) that when I experiment with a pre/post fix factor as either a random or fixed effect in the model, things are...weird. It seems like the haul (blocking variable) completely masks all variability/contribution that would otherwise go to the pre/post fix factor. The fix is not statistically significant when haul is also in the model. Which I think is misleading, because from the results of the complete pre/post model separation, we know that the FPC is pushed in different directions before and after the fix event.

## Analysis

Load packages
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(RColorBrewer)
library(cowplot)
library(fishmethods)
library(viridis)
library(patchwork)
library(lme4)

set.seed(401)
```



Read in data. 
```{r}
## logbook data
logbook <- read.csv("./data_folder/new_data_dump/DredgeSurvey_FishLogData_CatchComparisonHauls.csv") 

## catch data
catch_raw <- read.csv("./data_folder/new_data_dump/DredgeSurvey_CatchData_CatchComparisonHauls.csv") 

## specimen data
specimen <- read.csv("./data_folder/new_data_dump/DredgeSurvey_ScallopBioData_CatchComparisonHauls.csv")

```

Get some stats
```{r}
#how many hauls?
length(unique(logbook$haul)) #48 paired hauls hauls, 

a <- logbook %>% filter(cruise_year==2023)
length(unique(a$haul)) #38 paired hauls in 2023

b<- logbook %>% filter(cruise_year==2022)
length(unique(b$haul)) #10 paired hauls in 2022
```


Data wrangle.
```{r}
# join logbook and catch in a way that preserves zero catches
tidyr::expand_grid(logbook,
            dplyr::distinct(dplyr::transmute(catch_raw, samp_grp, rcode, comname, whole_haul, sample_type))) %>% #expand logbook to all catch types
  dplyr::left_join(catch_raw) %>% #join with the catch.This connects catch vales to gear_code id.
  # fill in zero catches
  tidyr::replace_na(list(samp_cnt = 0, samp_wt = 0)) %>%
  # filter for scallops
  dplyr::filter(rcode == 74120) -> catch # now you have records of scallop catch per size class (samp_grp) per gear type
  

# cpue will be samp_wt (or count) / area_swept_sqnm. This code is calculating CPUE for both weight and number of scallops
catch_cpue <- catch %>% 
    dplyr::mutate(cpue_cnt = samp_cnt/area_swept_sqnm,
           cpue_wt = samp_wt/area_swept_sqnm)

# compute sample factor for specimen data 
specimen %>%
  # group by tow, samp grp, and size to get n at size
  dplyr::group_by(tow, samp_grp, shell_height) %>%
  dplyr::summarize(count = n()) %>%
  # compute number measured per tow
  dplyr::group_by(tow, samp_grp) %>%
  dplyr::mutate(n_measured = n()) %>% dplyr::ungroup() %>%
  # join to catch data
  dplyr::left_join(catch, by = c("tow", "samp_grp")) %>%
  # compute sample factor
  dplyr::mutate(sample_factor = samp_cnt * (count / n_measured)) -> specimen

#separate large and small scallops for cpue
large <- catch_cpue %>% dplyr::filter(samp_grp == 1)
small <- catch_cpue %>% dplyr::filter(samp_grp == 2)

##Remove where both hauls are 0.
large_2 <- large %>% #no change
    dplyr::group_by(haul) %>%
    dplyr::filter(!all(cpue_cnt == 0)) %>%
    dplyr::ungroup()

small_2 <- small %>% #filtered out where both dredges in a haul caught nothing
    dplyr::group_by(haul) %>%
    dplyr::filter(!all(cpue_cnt == 0)) %>%
    dplyr::ungroup()

#code the factors as factors
large_m <- large_2 %>%
           dplyr::mutate(gear_code = base::factor(gear_code, levels=c("5","1")), haul = base::factor(haul))  #the levels argument specifies that Kodiak(5) is the base, to compare Homer(1) against
    

small_m <- small_2 %>%
           dplyr::mutate(gear_code = base::factor(gear_code, levels=c("5", "1")), haul = base::factor(haul)) #levels=c(1,5) ?

```


Add the pre or post fix column

```{r}
Homer_fix_table <- data.frame(haul=c(141, 150, 152, 154, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197), Homer_fix=(base::rep("post", 15)))

Homer_fix_table$haul <- factor(Homer_fix_table$haul)

Haul_post <- factor(c(141, 150, 152, 154, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197))

Haul_pre <- unique(large_m$haul)
Haul_pre <- Haul_pre[-c(34:48)]

Homer_pre_fix <- data.frame(haul=Haul_pre, Homer_fix=(base::rep("pre", length(Haul_pre))))

#make the table
Homer_fix_T <- rbind(Homer_pre_fix, Homer_fix_table)
Homer_fix_T$Homer_fix <- factor(Homer_fix_T$Homer_fix)

#join into other tavles
#str(left_join(large_m, Homer_fix, by= "haul" ))
#str(large_m)

large_m <- left_join(large_m, Homer_fix_T, by= "haul" ) #something is up here. The join isnt working. Homer_fix_T instead?
small_m <- left_join(small_m, Homer_fix_T, by= "haul" )

#add the homer fix to the size tables too?
specimen$haul <- factor(specimen$haul)
specimen <- left_join(specimen, Homer_fix_T, by="haul")

```


Graph of stuff, without the pre/post fix, to see where the change over happens
```{r}
library(scales)

xx <- ggplot(large_m) + aes(x=factor(haul), y=cpue_cnt, color=bed_name, shape=factor(gear_code)) + geom_point(size=4) +scale_color_brewer(type="qual", palette=3)+ scale_shape_manual(values=c(19, 15),labels=c("Kodiak dredge", "Homer dredge"))+
    theme_cowplot()+
    xlab("Haul")+ ylab("CPUE")+ #cpue count
    ggtitle("Large scallops")+
    labs(shape="Gear type", color= "Bed name")+
    scale_y_continuous(labels= label_comma())#+
    #facet_wrap(~Homer_fix, nrow=2)

yy <- ggplot(small_m) + aes(x=factor(haul), y=cpue_cnt, color=bed_name, shape=factor(gear_code)) + geom_point(size=4) +scale_color_brewer(type="qual", palette=3)+ scale_shape_manual(values=c(19, 15),labels=c("Kodiak dredge", "Homer dredge"))+
    theme_cowplot()+
    xlab("Haul")+ ylab("CPUE")+ #cpue count
    ggtitle("Small scallops")+
    labs(shape="Gear type", color= "Bed name")+
    scale_y_continuous(labels= label_comma())#+
    #facet_wrap(~Homer_fix, nrow=2)

yyy <- yy + theme(legend.position ="none")

cplot <- xx/yyy + plot_layout(guides="collect")
cplot

#plot to show the full thing where we noticed the maintenence that happened

ggsave("figures/exploratory.tiff", plot=cplot, height=10, width=20, units="in")

```


Plot pre and post dredge fix - WIP, need to add the fix
```{r}
x <-ggplot(large_m) + aes(x=factor(haul), y=cpue_cnt, color=bed_name, shape=factor(gear_code)) + geom_point(size=4) +scale_color_brewer(type="qual", palette=3)+ scale_shape_manual(values=c(19, 15),labels=c("Kodiak dredge", "Homer dredge"))+
    theme_cowplot()+
    xlab("Haul")+ ylab("CPUE")+
    ggtitle("Large scallops")+
    labs(shape="Gear type", color= "Bed name")+
    facet_wrap(~Homer_fix, nrow=2)+
    scale_y_continuous(labels= label_comma())



y<- ggplot(small_m) + aes(x=factor(haul), y=cpue_cnt, color=bed_name, shape=factor(gear_code)) + geom_point(size=4) +scale_color_brewer(type="qual", palette=3)+ scale_shape_manual(values=c(19, 15),labels=c("Kodiak dredge", "Homer dredge"))+
    theme_cowplot()+
    xlab("Haul")+ ylab("CPUE")+
    ggtitle("Small scallops")+
    labs(shape="Gear type", color= "Bed name")+
    facet_wrap(~Homer_fix, nrow=2)+
    scale_y_continuous(labels= label_comma())
x
y

x/y +plot_layout(guides="collect")

ggsave("figures/Split anova L.jpg", plot=x, height=10, width=20, units="in")
ggsave("figures/Split anova S.jpg", plot=y, height=10, width=20, units="in")
```



Split into pre and post- repair FPC tests
make sure the FPC is homer space -> kodiak space
```{r}
options(contrasts = rep("contr.sum", 2))

#large scallops
l_pre <- large_m %>% filter(Homer_fix == "pre")
l_post <- large_m %>% filter(Homer_fix == "post")


mod_L_pre_cnt <- lm(log(cpue_cnt+1) ~ gear_code + haul, data=l_pre)
mod_L_post_cnt <- lm(log(cpue_cnt+1) ~ gear_code + haul, data=l_post)

sum_L_pre <- summary(mod_L_pre_cnt)
sum_L_post <- summary(mod_L_post_cnt)

#small scallops

s_pre <- small_m %>% filter(Homer_fix == "pre")
s_post <- small_m %>% filter(Homer_fix == "post")


mod_S_pre_cnt <- lm(log(cpue_cnt+1) ~ gear_code + haul, data=s_pre)
mod_S_post_cnt <- lm(log(cpue_cnt+1) ~ gear_code + haul, data=s_post)

sum_S_pre <- summary(mod_S_pre_cnt)
sum_S_post <- summary(mod_S_post_cnt)

##################################
#get FPC estimator
###########################


#large pre repair
s_L_pre <- sum_L_pre$coefficients[2,2]  
g_L_pre <- sum_L_pre$coefficients[2,1]

FPC_large_pre <- exp(2*g_L_pre*(1+(0.5*(s_L_pre^2)))) #1.87

#large post repair
s_L_post <- sum_L_post$coefficients[2,2]  
g_L_post <- sum_L_post$coefficients[2,1]

FPC_large_post <- exp(2*g_L_post*(1+(0.5*(s_L_post^2)))) #0.88 #oof, pre and post repair are very different FPC's.

#small pre repair
s_S_pre <- sum_S_pre$coefficients[2,2]  
g_S_pre <- sum_S_pre$coefficients[2,1]

FPC_small_pre <- exp(2*g_S_pre*(1+(0.5*(s_S_pre^2)))) #1.64

#small post repair
s_S_post <- sum_S_post$coefficients[2,2]  
g_S_post <- sum_S_post$coefficients[2,1]

FPC_small_post <- exp(2*g_S_post*(1+(0.5*(s_S_post^2))))#0.87




##########################
#get confidence intervals
#####################
upper_CI_L_pre <- exp(2*g_L_pre + 1.96*2*s_L_pre)
lower_CI_L_pre <- exp(2*g_L_pre - 1.96*2*s_L_pre)

upper_CI_L_post <- exp(2*g_L_post + 1.96*2*s_L_post)
lower_CI_L_post <- exp(2*g_L_post - 1.96*2*s_L_post)

upper_CI_S_pre <- exp(2*g_S_pre + 1.96*2*s_S_pre)
lower_CI_S_pre <- exp(2*g_S_pre - 1.96*2*s_S_pre)

upper_CI_S_post <- exp(2*g_S_post + 1.96*2*s_S_post)
lower_CI_S_post <- exp(2*g_S_post - 1.96*2*s_S_post)








#get the combined FPC as well. for scallop count.
#yes
##large scallops combined FPC

mod_L_cnt <- lm(log(cpue_cnt+1) ~ gear_code + haul, data=large_m)

sum_L_cnt <- summary(mod_L_cnt)


##small scallops combined FPC
mod_S_cnt <- lm(log(cpue_cnt+1) ~ gear_code + haul, data=small_m)

sum_S_cnt <- summary(mod_S_cnt)

##FPC's
#large
s_L <- sum_L_cnt$coefficients[2,2]  
g_L <- sum_L_cnt$coefficients[2,1]

FPC_large_cnt <- exp(2*g_L*(1+(0.5*(s_L^2)))) #1.472
#small

s_S <- sum_S_cnt$coefficients[2,2]  
g_S <- sum_S_cnt$coefficients[2,1]

FPC_small_cnt <- exp(2*g_S*(1+(0.5*(s_S^2)))) #1.321

##get confidence intervals
#large
upper_CI_L <- exp(2*g_L + 1.96*2*s_L)
lower_CI_L <- exp(2*g_L - 1.96*2*s_L)
#small
upper_CI_S <- exp(2*g_S + 1.96*2*s_S)
lower_CI_S <- exp(2*g_S - 1.96*2*s_S)


upper_CI <- c(upper_CI_L_pre, upper_CI_L_post, upper_CI_L, upper_CI_S_pre, upper_CI_S_post, upper_CI_S )
lower_CI <- c(lower_CI_L_pre, lower_CI_L_post, lower_CI_L, lower_CI_S_pre,lower_CI_S_post, lower_CI_S)

###############
#make the table
##############

FPC <- c(FPC_large_pre, FPC_large_post, FPC_large_cnt, FPC_small_pre, FPC_small_post, FPC_small_cnt)
Category <- factor(x=c("large(pre)" , "large(post)", "large(combined)", "small(pre)", "small(post)", "small(combined)"), levels=c("large(pre)" , "large(post)", "large(combined)", "small(pre)", "small(post)", "small(combined)"))

scallop_FPC_table <- data.frame(Category, FPC)


scallop_FPC_table$Upper_CI <- upper_CI
scallop_FPC_table$Lower_CI <- lower_CI

scallop_FPC_table$repair <- factor(x=c("pre", "post", "combined", "pre", "post", "combined"), levels=c("combined","pre", "post"))

scallop_FPC_table#$repair <- reorder(scallop_FPC_table$repair, X=c("combined", "pre", "post"))



write.csv(scallop_FPC_table, "results/Scallop FPC Table.csv")

#oof. pre conclusions are different from post conclusions for large. No FPC applied for small, but still, oof.


```


FPC graph
```{r}
library(RColorBrewer)
#graph the FPC's and their confidence intervals, shwoing how they comapre to each other and also to 1.
ggplot(scallop_FPC_table) + aes(x=Category, y=FPC) + 
    geom_errorbar(aes(ymin=Lower_CI, ymax=Upper_CI)) +
    geom_point(size=4, aes(color=repair))+
    geom_hline(aes(yintercept=1), color="red", size=1, linetype="dashed")+
    theme_cowplot()+
    scale_color_brewer(palette = "Set1")+
    labs(color= "Homer dredge repair status")
    
#add cofidence intervals/error bars too. Geom_errorbar?
#and add a line at y=1 please
#manusal color scale
#get rid of "repair" or name it somethign better
#switch the pre and post factor order, so it goes pre then post

```

Mean and SD for both kodiak and homer scallops hauls, sep by L and S sscallops.
- supplmental slide
```{r}

```


Density graph exploration
```{r}
#any necessary data wrangling

#overall density comparison: homer v kodiak (see scallops_8)

#pre and post homer dredge fix: how did fixing homer dredge change density

#other comparisons?


```



Random effect or fixed effect (test for it) -  Homer dredge fix
Random effect did not work
Fixed effect was masked by the randomized block design
```{r}
#Q:
##do  I need to apply the options argument here, to switch it back to default??
##Also, do I calculate the FPC when there's other stuff going on... add this stuff to the uncertainty??
#############################################################################################################

large_m$Homer_fix <- factor(large_m$Homer_fix)
small_m$Homer_fix <- factor(small_m$Homer_fix)

#first establish the global model
##large
global_L <- lm(log(cpue_cnt+1) ~ gear_code + haul, data=large_m)

##small
global_S <- lm(log(cpue_cnt+1) ~ gear_code + haul, data=small_m)

#test random effects
random_L <- lmer(log(cpue_cnt+1) ~ gear_code + haul + (1|Homer_fix), data=large_m, REML=T) #this is probs the way to go
##I get a warning about the hessian matrix and singularity, indicating that I do not have enough data for a mixed effects model
summary(random_L)
summary(global_L)
ranef(random_L) #weird numbers

random_S <- lmer(log(cpue_cnt+1) ~ gear_code + haul + (1|Homer_fix), data=small_m, REML=T) 
#ok but this one runs without a hessian error.
summary(random_S)
ranef(random_S) #weird, saying the additional error from the Homer_fix is really really small, and I'm not so sure that is correct.
#maybe haul absorbs a lot of this error?

#try other model variations


#fixed effect model
fixed_L <- lm(log(cpue_cnt+1) ~ gear_code + haul + factor(Homer_fix), data=large_m)
AIC(global_L, random_L) #says mixed model is better of these two
AIC(global_L, fixed_L) #says thet're... the same
##haul is absorbing all of the change, masking homer_fix.
###hmm what to do about this
summary(fixed_L)

fixed_S <- lm(log(cpue_cnt+1) ~ gear_code + haul + factor(Homer_fix), data=small_m)
AIC(global_S, random_S) #nothing wins
AIC(global_S, fixed_S) #neitehr wins


#what if I take away haul
mod_L_no_haul <- lm(log(cpue_cnt+1) ~ gear_code + factor(Homer_fix), data=large_m)
mod_S_no_haul <- lm(log(cpue_cnt+1) ~ gear_code + factor(Homer_fix), data=small_m)

summary(mod_L_no_haul)
summary(mod_S_no_haul)

#gear code is not sig, when haul is removed. Duh, should have expected taht

```

